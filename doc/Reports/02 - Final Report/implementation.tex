\section{Implementation}
In the following we want to describe implementation specific details of both the simulator as well as the map editing application. We will elucidate problems we faced during the implementation and the integration of both applications and how we solved them. 
\subsection{Simulator}
Behind the user interface of the simulator a continuously running thread is mandated with updating the current state of the simulation with each tick, i.e. every 50ms by default. The thread execution is triggered by the globally governing SimulationController and its \textit{run}-method appears refreshingly simple (fig.~\ref{fig:animthread}). Despite the apparent simplicity the design of the thread posed a range of problems. As is usual for Java UI frameworks, JavaFX also prohibits changes to UI objects by any thread other the main application thread, forcing us to submit each update that is to be escalated to the interface as a \textit{runnable} object to said application thread's execution queue. To reduce scheduling overhead we kept the AnimationThread's main loop as simple as possible, resulting in no more than four calls to the mentioned execution queue. The calls to \textit{spawnRandomTrucks()} and \textit{spawnRandomCar()} depend on the car/truck-ratio currently observed on the map, i.e. either one of the method is called depending on the current deviation from the desired ratio. The \textit{updateCharts()} method of the \textit{ControlsController} retrieves the statistics of the simulation from the map and adds a new data point to each of the charts. This is done in 500 millisecond intervals.

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=\textwidth]{img/SD_animThread.pdf}
		\caption[Sequence Diagram of the Animation Thread]{Sequence Diagram of the Animation Thread}
		\label{fig:animthread}
	\end{center}

\end{figure}

With the multithreaded execution described above came concurrency related issues. The class Map contains a list of all vehicles currently present in the simulation. Whenever a vehicle is leaving the map, it notifies the SimulationController, which in turn removes the vehicle from the simulation. As the map's \textit{updateMap()} is constantly iterating through its list of vehicles, removing a vehicle from anywhere else than within this loop results in concurrency exceptions.

\begin{wrapfigure}{r}{0.45\textwidth}
	\begin{minipage}{0.45\textwidth}
		\begin{lstlisting}[caption={Car Removal}, label={lst:carRem}]
if(toBeRemoved.contains(v)){
	iter.remove();
	toBeRemoved.remove(v);
	continue;
}	
		\end{lstlisting}
	\end{minipage}
\end{wrapfigure}

In order to overcome this issue we considered both the traditional reader-writer-locking as well as the more advanced read-copy-update pattern, but eventually came to the conclusion that using either of them will introduce an additional scheduling (and implementation) overhead and hence only yield imperceptible performance improvements over the solution we employed (listing~\ref{lst:carRem}). As mentioned earlier, the \textit{updateMap()} method iterates through all existing vehicles with each tick. During the animation, the map keeps track of vehicles that are about to move off the map within the next tick. As soon as the iterator (\textit{iter}) points to a vehicle \textit{v} that is on the \textit{toBeRemoved} list, it is removed and the loop skips the iteration for this vehicle.

In order to ease the communication between model classes and the \textit{SimulationController} as well as the application classes \textit{MainApp} and \textit{EditorApp} we faced a design decision between the traditional observer pattern and the singleton pattern that allows static access to the required instances. We decided in favour of the singleton pattern, because the situations in which the model communicates with the \textit{SimulationController} are manifold and access to the singleton instance allows for fairly simple communication flows.

\subsection{Testing}
In order to meet all the requirements specified at the beginning of the project, testing forms an integral part in this process. Within the Agile development framework, we felt that Feature Driven Development (FDD) is most adaptable process suited for this project. Hence we decided to test the codes iteratively at the end of each development cycle. We foresaw that writing testing code in a concurrent fashion with the development team may not be an effective way, given the fact that the testing codes may not be working for the final product as incremental changes were made throughout the development. Therefore peer reviews were conducted at early stage to ensure  code quality is kept to standard, that is, each method should be written explicitly to address the problem that needs to be solved. In such manner, we can be assured of a rigid foundation (i.e. the software model) before we even attempt to adding more complicated features.

As the software becomes mature, unit tests were added to the project. We conducted unit testing in JUnit with the support of JemmyFX and ScenicView. JemmyFX is a third party library for testing JavaFX application. It is a test harness which allows the user to simulate user input, i.e. click buttons, entering data. In particular, JemmyFX defines how to get a list of scenes, nodes items, and get text of a \textit{javafx.scene.control.Label} (listing~\ref{lst:checkBox}). We have mainly used this for UI testing. 


\begin{minipage}{0.9\textwidth}
	\begin{lstlisting}[caption={Use JemmyFX syntax to find a checkBox element}, label={lst:checkBox}]

//Identifying the input checkBox element exist
assertEquals(CheckBox.class, new LabeledDock(scene.asParent(), checkBoxName, StringComparePolicy.EXACT).wrap().getControl().getClass());

//Find the label of the checkBox 
LabeledDock cb = new LabeledDock(scene.asParent(), checkBoxName, StringComparePolicy.EXACT);

	\end{lstlisting}
\end{minipage}

Using ScenicView helped us to understand what the UI was built from, allowing us and any other future developers to quickly and efficiently query the properties of a particular element, i.e. finding the properties of a JavaFX button (fig.~\ref{fig:scenicview}). ScenicView provides a tree structure and highlights the item upon it is selected. In the case of unable identifying an elements within the source code, this has been particularly helpful.  
\begin{figure}[h]
	\begin{center}
		\includegraphics[width=\textwidth]{img/scenicView.png}
		\caption[Identifying properties of Start button with ScenicView]{Identifying properties of Start button with ScenicView}
	\label{fig:scenicview}
	\end{center}
\end{figure}

Since we were trying to achieve a multithreaded application, we reached a point where it was impossible to test every functionality due to the level of nesting and threading was too deep for us to comprehend. Therefore we focused our unit testing mainly on major components (i.e. vehicles, map and the model), in order to ensure features within them work correctly - in return that the application would behave accordingly. With such approach, this gives us the confidence that our code works as we expect it to work. 

It is arguably that there were lots of areas need to be tested. From one perspective, one could argue that the number of test cases could be used as an indication on the software quality. But we believed that unit testing is not about finding bugs. It is to prove that all the components could work together as a whole.  With this mentality, we carried out tests to ensure that the foundation of our code is dependable - at least within the scope of what this project aims to achieve.  

We wrote our test cases in an automated fashion. This allowed us to reduce the workload on manual testing.  A log was produced at the end for every test scenario. This also allowed us to identify problems should each scenario fails. An illustration is shown in fig.~\ref{fig:testCase}. 

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=\textwidth]{img/testCase.png}
		\caption{A log is produced after a test execution}
	\label{fig:testCase}
	\end{center}
\end{figure}

In addition, we also looked at the organisation of our code base to further assess the code quality of our software.  To do so we used a commercial tool to analyse the architecture. We produced diagrams such architectural dependencies, heat maps, UML Class Diagrams, as well as metric reports to give us a visual cue on the software internally. We then feed back the analysis to the development team in order to make changes accordingly. For instance, the heat map gave an indication on the level of \textit{lineCount} against \textit{maxCyclomaticComplexity}, as shown in fig.~\ref{fig:heatmap}. The bigger the shape it is the more lines of codes there have been written for a class. The colour depth of a shape indicates the density of its max complexity. At one stage, we identified the \textit{maxCyclomaticComplexity} for the \textit{Car.class} is 58, we were able to reduce it to 21 for the final version.     

\begin{figure}[h]
	\begin{minipage}{\textwidth}
		\begin{center}
				\includegraphics[width=71mm,keepaspectratio ]{img/heatmap.png}
			\caption{Heat Map for the final version of the software}
			\label{fig:heatmap}	
		\end{center}
	\end{minipage}
\end{figure}

Fig.~\ref{fig:archIntDependency} illustrated the architectural dependency for our final product. We were assured that the outcome echoed to the requirement and design, though only a small portion of bi-directional calls were made internally. In most case, the architecture is preserved with uni-flow calls. There was no cluster found overall in this project, the architecture can be described more or less as clean, as shown in the figure. 

\begin{figure}[h]
	\begin{center}
			\includegraphics[width=\textwidth]{img/archIntDependency.png}
		\caption{Architecture Internal Dependency}
	\label{fig:archIntDependency}
	\end{center}
\end{figure}
\clearpage
\subsection{Map Editor}

\subsection{Graphical User Interface}
The majority of the effort with the editor application was on user interaction (UI) design and implementation. Recall the requirements from \ref{ss:req-editor} particularity those for usability (2.1-2.13). Fig.~\ref{fig:finalMapEditor} shows the resulting design chosen which the team felt had met the requirements in whole and one we hope is apparent when using the application to create a map.


\begin{figure}[h]
	\begin{center}
			\includegraphics[scale=0.45]{img/mapEditorFinal.png}
		\caption{Resulting map editor design}
		\label{fig:finalMapEditor}
	\end{center}
\end{figure}

\subsection{Flood Fill}
The basis of any map editor is the ability to tag defined areas of desktop real-estate representing a real world instance e.g. land mass. We began by constructing an X*Y cell grid, where X and Y are the number of cells horizontally and vertically and where X=Y. The smallest instance of a map was to be a 40x40 grid yielding 1,600 tiles each needing to be individually tagged. Clearly it was not realistic to expect the user to tag each cell individually. Even when removing the number of tiles that would be tagged using the road and intersection tools, large swathes of the map are left unfilled.  
A method was required that would not only fill the remaining tiles with the users choice of texture but do so intelligently. That is only fill empty cells within in a certain boundary so as not replace existing ones.  This is is better known as a flood fill algorithm and is listed as requirement 2.7 and 2.8 of section \ref{ss:reqs}

There are several techniques for implementing flood fill \cite{brennan2009} of which the 4-way stack based implementation is seen as the simplest and most elegant approach due to its Depth First Search (DFS) recursive property.  The appropriate psudocode is as follows:

% probably need a new listing for psudocode?
\begin{minipage}{0.9\textwidth}
	\begin{lstlisting}[caption={4-way stack based recursive flood fill}, label={lst:stackFloodFill}]
Flood-fill (node, target-tile, replacement-tile):
1. If target-tile is equal to replacement-tile, return.
2. If the tile of node is not equal to target-tile, return.
3. Set the tile of node to replacement-tile.
4. Flood-fill (west of node, target-tile, replacement-tile).
   Flood-fill (east of node, target-tile, replacement-tile).
   Flood-fill (north of node, target-tile, replacement-tile).
   Flood-fill (south of node, target-tile, replacement-tile).
5. Return.
	\end{lstlisting}
\end{minipage}

This procedure was extended with bounds checking in our multidimensional array to give the observable results.

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.8]{img/floodFill.png}
		\caption[Flood Fill]{Before and after the use of flood fill}
	\label{fig:floodfill}
	\end{center}
\end{figure}

Upon initial testing (ref. jerry's editor testing) the recursive approach performed exactly as expected with no functional issues  to report.  However, when the possibility of larger grid sizes was suggested, further testing revealed a fundamental flaw in this approach.  It was found that for a grid size larger than 65x65, a stack overflow would occur thus only partially filling the grid and causing the application to no longer respond.  With the ability to alter grid sizes implemented in later reversions of the simulator and editor applications, further investigation was warranted.

Approaching the literature, the stack over flow observation was commonly experienced and almost expected when using the recursive approach.  Mukherjee and Jana (2010, p.275) state:

 \begin{quotation}
A quick glance on the recursive variant of FloodFill function reveals that the recursive function makes four calls to itself at each step (for 4N connected region). Stack Overflow is the most common exception encountered while dealing with the recursive programs. Each time we call a function recursively, the function parameters, local variables and the return address of code (where to return when we are done with the recursion) are pushed to the stack. If the recursion is too deep, there may be overflowing of stack, where from there is no recovery.
 \end{quotation}
 
Possibly the simplest but least favoured approach was to alter the JVM's configuration parameters and increase the memory reserved for the stack.  Although this would be the simplest 'fix' it was not seen as a suitable solution given the many hardware and JVM configurations and further still, it was not a solution to the fundamental problem.

In the end the the recursive approach was deprecated while a 4-way queue based approach was implemented.  In contrast to the recursive implementation the queue based method is Breadth First Search (BFS) and uses a queue to store each new encountered tile.  The addition of two checks:

\begin{itemize}
  \item if the adjacent tile in question has not been already visited and
  \item if the tile is not of the target type
\end{itemize}

allowed for a tile to be added to the queue, replaced and dequeued in subsequent iterations. The relevant psudocode for the queue based approach is:

% probably need a new listing for psudocode?
\begin{minipage}{0.9\textwidth}
	\begin{lstlisting}[caption={4-way queue based flood fill}, label={lst:queueFloodFill}]
Flood-fill (node, target-tile, replacement-tile):
 1. If target-tile is equal to replacement-tile, return.
 2. Set Q to the empty queue.
 3. Add node to the end of Q.
 4. While Q is not empty: 
 5.     Set n equal to the last element of Q.
 6.     Remove last element from Q.
 7.     If the tile of n is equal to target-tile:
 8.         Set the tile of n to replacement-tile and mark 
 9			"n" as processed.
 10.        Add west node to end of Q if not yet processed.
 11.        Add east node to end of Q if not yet processed.
 12.        Add north node to end of Q if not yet processed.
 13.        Add south node to end of Q if not yet processed.
 14. Return.
	\end{lstlisting}
\end{minipage}

With this new revised function, grid size was no longer an issue and a flood fill of an empty 200x200 grid (larger than any suggested grid size) completed successfully without any noticeable delay.
\paragraph{}
To ensure the new approach would be indeed suitable for the set grid sizes, some simple measurements were taken.  The two algorithms were used to fill an empty grid with a 'grass' land tile, repeated three times and an average calculated.  The results shown in fig.\ref{fig:floodChart} clearly show that although the recursive stack based implementation performs on average 70\% faster, it was unable to function for grid widths greater than 60 in our set.  Although this may seem wholly a failure for the queue based implementation, it is important to point out that this equates to ~10ms difference. Not noticeable by any human operator.  Even more interesting was that the results quoted were based on First Time Run (FTR) values, immediately after launching the editor. Using the same two routines on subsequent occasions would yield repeated values as low as 10-16ms per fill.
 
\begin{figure}[h]
\centering
\begin{tikzpicture}
\begin{axis}[
    xlabel={Avg. Time [ms]},
    ylabel={Grid Width [no. of tiles]},
    xmin=0, xmax=120,
    ymin=0, ymax=120,
    xtick={0,20,40,60,80,100,120},
    ytick={0,20,40,60,80,100,120},
    legend pos=north west,
    ymajorgrids=true,
    grid style=dashed,
]
\addplot[
    color=red,
    mark=triangle,
    ]
    coordinates {
    (10,30)(11,40)(19,50)(21,60)
    };
\addplot[
    color=blue,
    mark=square,
    ]
    coordinates {
    (20,30)(22,40)(33,50)(54,60)(80,80)(110,100)
    };
    \legend{Stack, Queue}
\end{axis}
\end{tikzpicture}
\caption{Average execution time for flood fill}
\label{fig:floodChart}
\end{figure}

It must be noted that the new method is no longer as concise as a definition compared to the original but it was a subtle sacrifice for the benefits it yielded.

